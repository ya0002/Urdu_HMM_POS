{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-09T22:26:12.406904Z",
     "iopub.status.busy": "2025-06-09T22:26:12.406582Z",
     "iopub.status.idle": "2025-06-09T22:26:13.509376Z",
     "shell.execute_reply": "2025-06-09T22:26:13.508312Z",
     "shell.execute_reply.started": "2025-06-09T22:26:12.406876Z"
    },
    "id": "dLEs7-LjE6mu",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T20:58:54.643945Z",
     "iopub.status.busy": "2025-06-17T20:58:54.643337Z",
     "iopub.status.idle": "2025-06-17T20:58:54.647780Z",
     "shell.execute_reply": "2025-06-17T20:58:54.647030Z",
     "shell.execute_reply.started": "2025-06-17T20:58:54.643922Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "\n",
    "pipe = pipeline(\"translation\", model=\"facebook/nllb-200-distilled-600M\")\n",
    "# pipe(\"ارے بھائی، آپ کیسے ہیں؟\",src_lang=\"urd_Arab\",tgt_lang=\"eng_Latn\")[0].get('translation_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-vpV_UhacpNO"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BTR1Prv-igdQ"
   },
   "source": [
    "# Urdu Monolingual Corpus\n",
    "\n",
    "https://lindat.mff.cuni.cz/repository/xmlui/handle/11858/00-097C-0000-0023-65A9-5#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T20:43:06.437828Z",
     "iopub.status.busy": "2025-06-17T20:43:06.437490Z",
     "iopub.status.idle": "2025-06-17T20:43:32.449862Z",
     "shell.execute_reply": "2025-06-17T20:43:32.448910Z",
     "shell.execute_reply.started": "2025-06-17T20:43:06.437808Z"
    },
    "id": "XgKSUZcGiwjO",
    "outputId": "5e35603f-b0b5-4d72-8c37-cf4b232fba94",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! curl --remote-name-all https://lindat.mff.cuni.cz/repository/xmlui/bitstream/handle/11858/00-097C-0000-0023-65A9-5{/urdu-tagged-corpus.gz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T20:43:32.451876Z",
     "iopub.status.busy": "2025-06-17T20:43:32.451633Z",
     "iopub.status.idle": "2025-06-17T20:43:39.476932Z",
     "shell.execute_reply": "2025-06-17T20:43:39.475897Z",
     "shell.execute_reply.started": "2025-06-17T20:43:32.451854Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "! yes y | gunzip urdu-tagged-corpus.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-17T21:10:16.110564Z",
     "iopub.status.busy": "2025-06-17T21:10:16.109647Z",
     "iopub.status.idle": "2025-06-17T21:10:16.116867Z",
     "shell.execute_reply": "2025-06-17T21:10:16.116112Z",
     "shell.execute_reply.started": "2025-06-17T21:10:16.110534Z"
    },
    "id": "7OEhbRsslKVd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_tag_file(filepath,max_lines=1000000, translate=True,output_file=\"translated.txt\"):\n",
    "    sentences = []\n",
    "    translated_sentences = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in tqdm(file,total=max_lines):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue  # skip empty lines\n",
    "            tokens = []\n",
    "            translated_sent = \"\"\n",
    "            for item in line.split():\n",
    "                if '|' in item:\n",
    "                    word, tag = item.rsplit('|', 1)\n",
    "                    tokens.append((word, tag))\n",
    "                    if translate:\n",
    "                      # t_word = pipe(word,src_lang=\"urd_Arab\",tgt_lang=\"eng_Latn\")[0].get('translation_text')\n",
    "                        translated_sent = translated_sent + f\" {word}\"\n",
    "            if tokens:\n",
    "                sentences.append(tokens)\n",
    "                if translate:\n",
    "                  # print(translated_sent)\n",
    "                    translated_sentences.append(\n",
    "                      pipe(\n",
    "                          translated_sent,src_lang=\"urd_Arab\",tgt_lang=\"eng_Latn\"\n",
    "                      )[0].get('translation_text') +\"  :: \"+ translated_sent\n",
    "                  )\n",
    "            \n",
    "            if len(sentences)==max_lines:\n",
    "                break\n",
    "          \n",
    "            with open(output_file, \"a\", encoding=\"utf-8\") as f_out:\n",
    "                f_out.write(translated_sentences[-1] + \"\\n\")\n",
    "        \n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03bNdxSGlcTB",
    "outputId": "b9db6f21-c38a-438a-c9f8-b394235ca34a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# filepath = \"urmono.tag\" ## in windows\n",
    "filepath = 'urdu-tagged-corpus' ## in linux\n",
    "\n",
    "\n",
    "sentences = parse_tag_file(filepath, \n",
    "                           max_lines=10000000, \n",
    "                           translate=True\n",
    "                          )\n",
    "\n",
    "# Example\n",
    "print(f\"Total sentences: {len(sentences)}\")\n",
    "print(\"First sentence:\", sentences[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZLI16mLc-6P"
   },
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpAqtHlOdAhM"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "random.shuffle(sentences)\n",
    "split_idx = int(0.8 * len(sentences))\n",
    "train_sents = sentences[:split_idx]\n",
    "test_sents = sentences[split_idx:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdM5XEaIdDrw"
   },
   "source": [
    "# HMM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_wNkbw9KdIL0"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tag.hmm import HiddenMarkovModelTrainer\n",
    "import dill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EK0e36ndBCX"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "trainer = HiddenMarkovModelTrainer()\n",
    "tagger = trainer.train_supervised(train_sents)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = tagger.accuracy(test_sents)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "with open(\"urdu_hmm_tagger.pkl\", \"wb\") as f:\n",
    "    dill.dump(tagger, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"urdu_hmm_tagger.pkl\", \"rb\") as f:\n",
    "    tagger = dill.load(f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qvpl-h5ydW2N"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LoVQGTBhdMGf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged: [('آج', 'NN'), ('موسم', 'NN'), ('اچھا', 'ADJ'), ('ہے', 'VB')]\n"
     ]
    }
   ],
   "source": [
    "urdu_sentence = [\"آج\", \"موسم\", \"اچھا\", \"ہے\"]\n",
    "tagged = tagger.tag(urdu_sentence)\n",
    "print(\"Tagged:\", tagged)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "lllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
